---
title: "How Does Heterogeneous Label Noise Impact Generalization in Neural
Nets?"
collection: publications
permalink: /publication/label_noise
excerpt: '**Bidur Khanal**, and Christopher Kanan. **How Does Heterogeneous Label Noise Impact Generalization in Neural
Nets?** In International Symposium on Visual Computing, pp. 229-241. Springer, Cham, 2021.'

date: 2021-10-04
venue: 'International Symposium on Visual Computing'
---
Abstract: Incorrectly labeled examples, or label noise, is common in real-world computer vision datasets. While the impact of label noise on learning in deep neural networks has been studied in prior work, these studies have exclusively
focused on homogeneous label noise, i.e., the degree of label noise is the same
across all categories. However, in the real-world, label noise is often heterogeneous, with some categories being affected to a greater extent than others. Here,
we address this gap in the literature. We hypothesized that heterogeneous label
noise would only affect the classes that had label noise unless there was transfer
from those classes to the classes without label noise. To test this hypothesis, we
designed a series of computer vision studies using MNIST, CIFAR-10, CIFAR100, and MS-COCO where we imposed heterogeneous label noise during the
training of multi-class, multi-task, and multi-label systems. Our results provide
evidence in support of our hypothesis: label noise only affects the class affected
by it unless there is transfer.

**Bidur Khanal**, and Christopher Kanan. **How Does Heterogeneous Label Noise Impact Generalization in Neural
Nets?** In International Symposium on Visual Computing, pp. 229-241. Springer, Cham, 2021.


[Download paper here](https://arxiv.org/pdf/2106.15475.pdf)


